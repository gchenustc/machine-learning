{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9a90aafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n",
    "from math import log\n",
    "import pickle\n",
    "import operator\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0d7119ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creatDataSet():\n",
    "    dataset = [[0,0,0,0,'no'],\n",
    "               [0,0,0,1,'no'],\n",
    "               [0,1,0,1,'yes'],\n",
    "               [0,1,1,0,'yes'],\n",
    "               [0,0,0,0,'no'],\n",
    "               [1,0,0,0,'no'],\n",
    "               [1,0,0,1,'no'],\n",
    "               [1,1,1,1,'yes'],\n",
    "               [1,0,1,2,'yes'],\n",
    "               [2,0,1,2,'yes'],\n",
    "               [2,0,1,1,'yes'],\n",
    "               [2,1,0,1,'yes'],\n",
    "               [2,1,0,2,'yes'],\n",
    "               [2,0,0,0,'no']]\n",
    "    feature_names = ['Age','Work','Home','Loan']\n",
    "    return dataset, feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "95da6180",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTree(dataset, feature_names, best_feature_order):\n",
    "    \"\"\"\n",
    "    创建决策树\n",
    "    feature_names: dataset每一列的特征名\n",
    "    feature_order：决策树的特征顺序（优先级高的在前面），为列表\n",
    "    返回值：决策树字典\n",
    "    \"\"\"\n",
    "    labels = [each[-1] for each in dataset]\n",
    "    \n",
    "    # 递归结束条件 -- 1.标签只有一个类别 2.已经使用完所有的特征\n",
    "    if labels.count(labels[0]) == len(labels):\n",
    "        return labels[0]\n",
    "    if len(dataset[0]) == 1:\n",
    "        return majorityCnt(labels)  # 所有特征都用完，此分支的类别由多数标签决定\n",
    "    \n",
    "    # 递归\n",
    "    # 确定当前最佳标签\n",
    "    best_feature_index = choosBestFeature(dataset)\n",
    "    \n",
    "    #print(best_feature_index)\n",
    "    #print(len(dataset[0]))\n",
    "    \n",
    "    best_feature_name = feature_names[best_feature_index]\n",
    "    best_feature_order.append(best_feature_name)\n",
    "    del feature_names[best_feature_index]\n",
    "    \n",
    "    # 创建树根\n",
    "    my_tree = {best_feature_name:{}}\n",
    "    \n",
    "    # 对最佳标签进行操作\n",
    "    feature_values = [each[best_feature_index] for each in dataset]\n",
    "    unique_feature_values = set(feature_values)\n",
    "    \n",
    "    for value in unique_feature_values:\n",
    "        sub_feature_names = feature_names[:]\n",
    "        my_tree[best_feature_name][value] = createTree(splitDataSet(dataset,best_feature_index,value), sub_feature_names, best_feature_order)\n",
    "    \n",
    "    return my_tree\n",
    "\n",
    "    \n",
    "def majorityCnt(labels):\n",
    "    \"\"\"\n",
    "    返回标签名\n",
    "    输入：列表\n",
    "    输出：字符串\n",
    "    \"\"\"\n",
    "    labels_count = {}\n",
    "    for label in labels:\n",
    "        if label not in labels_count:\n",
    "            labels_count[label] = 0\n",
    "        else:\n",
    "            labels_count[label] += 1\n",
    "    return sorted(labels_count.items(), \n",
    "                  key=operator.itemgetter(1),reverse=True)[0][0]\n",
    "\n",
    "\n",
    "def choosBestFeature(dataset):\n",
    "    \"\"\"\n",
    "    返回值：index for feature\n",
    "    \"\"\"\n",
    "    base_entropy = calcEntropy(dataset)\n",
    "    best_gain = 0\n",
    "    best_feature_index = None\n",
    "    \n",
    "    n_features = len(dataset[0]) - 1\n",
    "    #print(f\"n_features:{n_features}\")\n",
    "    #print(f\"base_entropy:{base_entropy}\")\n",
    "    #print(dataset)\n",
    "    \n",
    "    for feature_index in range(n_features):\n",
    "        \n",
    "        feature_values = [each[feature_index] for each in dataset]\n",
    "        uniqe_feature_values = set(feature_values)\n",
    "        \n",
    "        new_entropy = 0\n",
    "        for uniqe_feature_value in uniqe_feature_values:\n",
    "            sub_dataset = splitDataSet(dataset,feature_index,uniqe_feature_value)\n",
    "            single_entropy = calcEntropy(sub_dataset)\n",
    "            prop = len(sub_dataset) / float(len(dataset))\n",
    "            new_entropy += prop*single_entropy\n",
    "        new_gain = base_entropy - new_entropy\n",
    "        #print(best_gain, new_gain)\n",
    "        if new_gain > best_gain:\n",
    "            best_gain = new_gain\n",
    "            best_feature_index = feature_index\n",
    "        \n",
    "    return best_feature_index\n",
    "    \n",
    "\n",
    "def calcEntropy(dataset):\n",
    "    \n",
    "    labels = [each[-1] for each in dataset]\n",
    "    labels_count = {}\n",
    "    \n",
    "    for label in labels:\n",
    "        if label not in labels_count:\n",
    "            labels_count[label] = 1\n",
    "        else:\n",
    "            labels_count[label] += 1\n",
    "    #print(labels_count)\n",
    "    #print(labels_count)\n",
    "    entropy = 0\n",
    "    for label_name in labels_count:\n",
    "        prop = labels_count[label_name] / float(len(labels))\n",
    "        #print(prop)\n",
    "        label_entropy = prop * log(prop,2) if prop != 0 else 0\n",
    "        entropy -= label_entropy\n",
    "    #print(entropy)\n",
    "        \n",
    "    return entropy\n",
    "\n",
    "\n",
    "def splitDataSet(dataset, feature_index, value):\n",
    "    new_dataset = []\n",
    "    for line in dataset:\n",
    "        if line[feature_index] == value:\n",
    "            new_dataset.append(line[:feature_index] + line[feature_index+1:])\n",
    "    #print(np.array(dataset).shape, np.array(new_dataset).shape)\n",
    "    return new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "88b21998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Work': {0: {'Home': {0: 'no', 1: 'yes'}}, 1: 'yes'}}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset, feature_names = creatDataSet()\n",
    "best_feature_order = []\n",
    "tree = createTree(dataset, feature_names, best_feature_order)\n",
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bbb06a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('a', 2), ('b', 1), ('c', 3)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_ = {'a':2,'b':1,'c':3}\n",
    "print(dict_.items())\n",
    "sorted(dict_.items(), key=operator.itemgetter(1))\n",
    "len(dict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9e81079e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log(4,2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
